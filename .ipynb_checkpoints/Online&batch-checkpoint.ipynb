{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports:\n",
    "import numpy as np\n",
    "import math, os, pickle\n",
    "from numpy import genfromtxt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "    '''Printing pretty'''\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "    \n",
    "def netPlot(instance, error):\n",
    "    ''' Plot the error '''\n",
    "    instance = list(range(0, instance))\n",
    "    with plt.rc_context({'axes.edgecolor':'orange', 'xtick.color':'red', 'ytick.color':'green', 'figure.facecolor':'white'}):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(instance, error)\n",
    "        ax.set(xlabel='batch numebr (s)', ylabel='error (net)',\n",
    "               title='Average Net Error for each batch run')\n",
    "        ax.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def sigmoid(x):  \n",
    "    '''Hidden layer activation always, single output activation function'''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x): \n",
    "    '''back prop on activation hidden'''\n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A): \n",
    "    ''' activation of output for multi class'''\n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum()\n",
    "\n",
    "def load_objects(file):\n",
    "    with open(file, 'rb') as input:\n",
    "        return pickle.load(input)\n",
    "    \n",
    "def save_it_all(obj, filename):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def saveNet(wh, bh, wo, bo, fileName):\n",
    "    weights = {\"wh\":wh, \"bh\":bh, \"wo\":wo, \"bo\":bo}\n",
    "    save_it_all(weights, fileName)\n",
    "    \n",
    "def getArrayFromFile(name):\n",
    "    array = genfromtxt(name, delimiter=',')\n",
    "    return array\n",
    "\n",
    "def mapTargetsToEncoded(targets, tMap):\n",
    "    '''for multi class we need to replace the single target eith ethe encoded target'''\n",
    "    newTargets = []\n",
    "    for item in targets.tolist():\n",
    "        newTargets.append(tMap[int(item[0])])\n",
    "    return newTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-36-84546ffb6a91>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-84546ffb6a91>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    zetaHidden = np.dot(inputInstance, weightHidden) + biasHidden\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def nn(inputInstance, targetInstance, weightHidden, biasHidden, weightOutput, biasOutput, ohe):\n",
    "    '''neural net'''\n",
    "        # feed forward\n",
    "        # Phase 1 inputs fed through to hidden\n",
    "        zetaHidden = np.dot(inputInstance, weightHidden) + biasHidden\n",
    "        activationHidden = sigmoid(zetaHidden)\n",
    "        \n",
    "        # Phase 2 hidden fed through to the output\n",
    "        zetaOutput = np.dot(activationHidden, weightOutput) + biasOutput\n",
    "        if ohe == 1 :\n",
    "            activationOutput = softmax(zetaOutput)\n",
    "        else:\n",
    "            activationOutput = sigmoid(zetaOutput)\n",
    "        #### backpropigate with the cross entropy cost function \n",
    "        # phase one \n",
    "        derivativecost_zetaOutput = activationOutput - targetInstance\n",
    "\n",
    "\n",
    "        derivativeZetaOutput_derivatieWeightOutput = activationHidden\n",
    "\n",
    "\n",
    "        derivativecost_weightOutput = np.dot(derivativeZetaOutput_derivatieWeightOutput.T, derivativecost_zetaOutput)\n",
    "\n",
    "\n",
    "        derivativecost_biasOutput = derivativecost_zetaOutput\n",
    "\n",
    "        #     # phase two\n",
    "        derivativeZetaOutput_derivativeActivationHidden = weightOutput\n",
    "\n",
    "        derivativeCost_derivativeActivationHidden = np.dot(derivativecost_zetaOutput , derivativeZetaOutput_derivativeActivationHidden.T)\n",
    "\n",
    "        derivativeActivationHidden_derivativeZetaHidden = sigmoid_der(zetaHidden)\n",
    "\n",
    "        derivativeZetaHidden_derivativeWeightHidden = inputInstance\n",
    "\n",
    "        derivativeCost_weightHidden = np.dot(derivativeZetaHidden_derivativeWeightHidden.T, derivativeActivationHidden_derivativeZetaHidden * derivativeCost_derivativeActivationHidden)\n",
    "\n",
    "        derivativeCost_biasHidden = derivativeCost_derivativeActivationHidden * derivativeActivationHidden_derivativeZetaHidden\n",
    "\n",
    "\n",
    "        #  update Weights \n",
    "\n",
    "        weightHidden -= learningRate * derivativeCost_weightHidden\n",
    "\n",
    "        biasHidden -= learningRate * derivativeCost_biasHidden.sum(axis=0)\n",
    "\n",
    "        weightOutput -= learningRate * derivativecost_weightOutput\n",
    "\n",
    "        biasOutput -= learningRate * derivativecost_biasOutput.sum(axis=0)\n",
    "        \n",
    "        loss = np.sum(-targetInstance * np.log(activationOutput))\n",
    "        \n",
    "        return (loss, weightHidden, biasHidden, weightOutput, biasOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # load in normalized data set \n",
    "    # dataSetFile, saveFile, testFile = (\"normalizeFish.csv\", \"./fishNet.pkl\", \"normalizeFishTest.csv\")\n",
    "    dataSetFile, saveFile, testFile = (\"normDigit.csv\", \"./digitNet.pkl\", \"testDigit.csv\")\n",
    "    data = getArrayFromFile(dataSetFile)\n",
    "    inputs = data[:,0:data.shape[1]-1] # get the input values\n",
    "    targets = data[:, data.shape[1]-1:data.shape[1]] # get the class values\n",
    "    ohe = 0\n",
    "\n",
    "    if np.unique(targets).shape[0] > 2:\n",
    "        targetMap = load_objects(\"./TestingdigitTargetCleanDict.pkl\")\n",
    "        oneHotTargets = np.asarray(mapTargetsToEncoded(targets, targetMap), dtype=np.float32)\n",
    "        ohe = 1\n",
    "\n",
    "    instances = inputs.shape[0]\n",
    "    attributes = inputs.shape[1]\n",
    "\n",
    "    numInputNodes = attributes\n",
    "    numOutputNodes = 1 if np.unique(targets).shape[0] == 2 else np.unique(targets).shape[0]\n",
    "    numHiddenNodes = int((2/3)*(numInputNodes+numOutputNodes))\n",
    "\n",
    "    print(\"Input node num: \"+ str(numInputNodes))\n",
    "    print(\"Hidden node num: \"+ str(numHiddenNodes))\n",
    "    print(\"Output node num: \" + str(numOutputNodes))\n",
    "\n",
    "    lowRange = (-1/math.sqrt(numInputNodes))\n",
    "    highRange = math.fabs(lowRange)\n",
    "\n",
    "    weightHidden = np.random.uniform(low=lowRange, high=highRange, size=(numInputNodes, numHiddenNodes, ))\n",
    "    biasHidden = np.random.uniform(low=lowRange, high=highRange, size=(numHiddenNodes))\n",
    "\n",
    "    weightOutput = np.random.uniform(low=lowRange, high=highRange, size=(numHiddenNodes, numOutputNodes))\n",
    "    biasOutput = np.random.uniform(low=lowRange, high=highRange, size=(numOutputNodes))\n",
    "\n",
    "    print()\n",
    "    print(str(weightHidden.shape))\n",
    "    print(str(biasHidden.shape))\n",
    "    print(str(weightOutput.shape))\n",
    "    print(str(biasOutput.shape))\n",
    "\n",
    "    print()\n",
    "    print(str(inputs.shape))\n",
    "    print()\n",
    "    learningRate = .01\n",
    "\n",
    "    errorCost = []\n",
    "    batchError = []\n",
    "\n",
    "    for epoch in range(55):\n",
    "        trackedNetError= []\n",
    "        print(\"------------Epoch: \"+str(epoch)+\"--\")\n",
    "        for instanceRow in range(0, instances):\n",
    "\n",
    "            inputInstance = np.array([inputs[instanceRow]])\n",
    "            if ohe == 1:\n",
    "                targetInstance = np.array([oneHotTargets[instanceRow]])\n",
    "            else:\n",
    "                targetInstance = targets[instanceRow]\n",
    "\n",
    "            loss, weightHidden, biasHidden, weightOutput, biasOutput = nn(inputInstance, targetInstance, weightHidden, biasHidden, weightOutput, biasOutput, ohe)\n",
    "\n",
    "            trackedNetError.append(loss)\n",
    "        avg_err = statistics.mean(trackedNetError)\n",
    "        print(\"Loss: \"+str(avg_err))\n",
    "        batchError.append(avg_err)\n",
    "        print()\n",
    "    \n",
    "    netPlot(55, batchError)\n",
    "    saveNet(weightHidden, biasHidden, weightOutput, biasOutput, saveFile)\n",
    "    Classify(testFile, saveFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify(fileName, NetName):\n",
    "    data = getArrayFromFile(fileName)\n",
    "    #data = np.array([getArrayFromFile(\"normalizeFishTest.csv\")])\n",
    "    inputs = data[:,0:data.shape[1]-1] # get the input values\n",
    "    targets = data[:, data.shape[1]-1:data.shape[1]] # get the class values\n",
    "\n",
    "    ohe = 0\n",
    "\n",
    "    if np.unique(targets).shape[0] > 2:\n",
    "        ohe = 1\n",
    "\n",
    "    instances = inputs.shape[0]\n",
    "    attributes = inputs.shape[1]\n",
    "\n",
    "    numInputNodes = attributes\n",
    "    numOutputNodes = 1 if np.unique(targets).shape[0] == 2 else np.unique(targets).shape[0]\n",
    "    numHiddenNodes = int((2/3)*(numInputNodes+numOutputNodes))\n",
    "\n",
    "    nnw = load_objects(netName)\n",
    "\n",
    "    weightHidden = nnw[\"wh\"]\n",
    "    biasHidden = nnw[\"bh\"]\n",
    "    weightOutput = nnw[\"wo\"]\n",
    "    biasOutput = nnw[\"bo\"]\n",
    "\n",
    "    correct = 0\n",
    "    for instanceRow in range(0, instances):\n",
    "\n",
    "        inputInstance = np.array([inputs[instanceRow]])\n",
    "        target = int(targets[instanceRow][0])\n",
    "\n",
    "        zetaHidden = np.dot(inputInstance, weightHidden) + biasHidden\n",
    "        activationHidden = sigmoid(zetaHidden)\n",
    "\n",
    "        zetaOutput = np.dot(activationHidden, weightOutput) + biasOutput\n",
    "        if ohe == 1:\n",
    "            activationOutput = softmax(zetaOutput)\n",
    "        else:\n",
    "            activationOutput = sigmoid(zetaOutput)\n",
    "\n",
    "        pred = np.where(activationOutput==np.max(activationOutput))[1][0] if ohe == 1 else int(round(activationOutput[0][0]))\n",
    "\n",
    "        if(pred == target):\n",
    "            correct = correct + 1\n",
    "\n",
    "    totalPercentRight = (correct/instances)*100\n",
    "    print(\"Correct for: \"+str(totalPercentRight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input node num: 64\n",
      "Hidden node num: 49\n",
      "Output node num: 10\n",
      "\n",
      "(64, 49)\n",
      "(49,)\n",
      "(49, 10)\n",
      "(10,)\n",
      "\n",
      "(3823, 64)\n",
      "\n",
      "------------Epoch: 0--\n",
      "Loss: 0.44391185234744895\n",
      "\n",
      "------------Epoch: 1--\n",
      "Loss: 0.17924220275736358\n",
      "\n",
      "------------Epoch: 2--\n",
      "Loss: 0.1666201432844629\n",
      "\n",
      "------------Epoch: 3--\n",
      "Loss: 0.13748951537657222\n",
      "\n",
      "------------Epoch: 4--\n",
      "Loss: 0.10989330377380496\n",
      "\n",
      "------------Epoch: 5--\n",
      "Loss: 0.10723093217966471\n",
      "\n",
      "------------Epoch: 6--\n",
      "Loss: 0.13615724645126023\n",
      "\n",
      "------------Epoch: 7--\n",
      "Loss: 0.11629585788819302\n",
      "\n",
      "------------Epoch: 8--\n",
      "Loss: 0.08925578938255177\n",
      "\n",
      "------------Epoch: 9--\n",
      "Loss: 0.07680584474299351\n",
      "\n",
      "------------Epoch: 10--\n",
      "Loss: 0.09422184436502909\n",
      "\n",
      "------------Epoch: 11--\n",
      "Loss: 0.0979679518888574\n",
      "\n",
      "------------Epoch: 12--\n",
      "Loss: 0.08579496022720128\n",
      "\n",
      "------------Epoch: 13--\n",
      "Loss: 0.076620822938016\n",
      "\n",
      "------------Epoch: 14--\n",
      "Loss: 0.06919927752902925\n",
      "\n",
      "------------Epoch: 15--\n",
      "Loss: 0.06609959407774905\n",
      "\n",
      "------------Epoch: 16--\n",
      "Loss: 0.09052935438160335\n",
      "\n",
      "------------Epoch: 17--\n",
      "Loss: 0.080214290021632\n",
      "\n",
      "------------Epoch: 18--\n",
      "Loss: 0.07503003758511685\n",
      "\n",
      "------------Epoch: 19--\n",
      "Loss: 0.0536293013539286\n",
      "\n",
      "------------Epoch: 20--\n",
      "Loss: 0.0410203784025451\n",
      "\n",
      "------------Epoch: 21--\n",
      "Loss: 0.02385479865570469\n",
      "\n",
      "------------Epoch: 22--\n",
      "Loss: 0.03518700325883327\n",
      "\n",
      "------------Epoch: 23--\n",
      "Loss: 0.040170124264586535\n",
      "\n",
      "------------Epoch: 24--\n",
      "Loss: 0.02246221868804943\n",
      "\n",
      "------------Epoch: 25--\n",
      "Loss: 0.03444392149414554\n",
      "\n",
      "------------Epoch: 26--\n",
      "Loss: 0.05265850701859889\n",
      "\n",
      "------------Epoch: 27--\n",
      "Loss: 0.06010197523551331\n",
      "\n",
      "------------Epoch: 28--\n",
      "Loss: 0.04400049957383351\n",
      "\n",
      "------------Epoch: 29--\n",
      "Loss: 0.05970124961852827\n",
      "\n",
      "------------Epoch: 30--\n",
      "Loss: 0.04132753510899233\n",
      "\n",
      "------------Epoch: 31--\n",
      "Loss: 0.048439909558216705\n",
      "\n",
      "------------Epoch: 32--\n",
      "Loss: 0.071204092587718\n",
      "\n",
      "------------Epoch: 33--\n",
      "Loss: 0.07973340754827998\n",
      "\n",
      "------------Epoch: 34--\n",
      "Loss: 0.04903174405307432\n",
      "\n",
      "------------Epoch: 35--\n",
      "Loss: 0.03862611800817351\n",
      "\n",
      "------------Epoch: 36--\n",
      "Loss: 0.03543377681135762\n",
      "\n",
      "------------Epoch: 37--\n",
      "Loss: 0.03737422182168871\n",
      "\n",
      "------------Epoch: 38--\n",
      "Loss: 0.07950589158888027\n",
      "\n",
      "------------Epoch: 39--\n",
      "Loss: 0.08784556315401242\n",
      "\n",
      "------------Epoch: 40--\n",
      "Loss: 0.11978686954345918\n",
      "\n",
      "------------Epoch: 41--\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
